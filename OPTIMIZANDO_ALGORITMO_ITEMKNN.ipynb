{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdaZ4UcPsq88"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemKNN:\n",
        "    '''\n",
        "    ItemKNN(n_sims = 100, lmbd = 20, alpha = 0.5, session_key = 'SessionId', item_key = 'ItemId', time_key = 'Time')\n",
        "    Item-to-item predictor that computes the the similarity to all items to the given item.\n",
        "    Similarity of two items is given by:\n",
        "    .. math::\n",
        "        s_{i,j}=\\sum_{s}I\\{(s,i)\\in D & (s,j)\\in D\\} / (supp_i+\\\\lambda)^{\\\\alpha}(supp_j+\\\\lambda)^{1-\\\\alpha}\n",
        "    Parameters\n",
        "    --------\n",
        "    n_sims : int\n",
        "        Only give back non-zero scores to the N most similar items. Should be higher or equal than the cut-off of your evaluation. (Default value: 100)\n",
        "    lmbd : float\n",
        "        Regularization. Discounts the similarity of rare items (incidental co-occurrences). (Default value: 20)\n",
        "    alpha : float\n",
        "        Balance between normalizing with the supports of the two items. 0.5 gives cosine similarity, 1.0 gives confidence (as in association rules).\n",
        "    session_key : string\n",
        "        header of the session ID column in the input file (default: 'SessionId')\n",
        "    item_key : string\n",
        "        header of the item ID column in the input file (default: 'ItemId')\n",
        "    time_key : string\n",
        "        header of the timestamp column in the input file (default: 'Time')\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_sims=100, lmbd=20, alpha=0.5, session_key='SessionId', item_key='ItemId', time_key='Time'):\n",
        "        self.n_sims = n_sims\n",
        "        self.lmbd = lmbd\n",
        "        self.alpha = alpha\n",
        "        self.item_key = item_key\n",
        "        self.session_key = session_key\n",
        "        self.time_key = time_key\n",
        "\n",
        "    def fit(self, data):\n",
        "        '''\n",
        "        Trains the predictor.\n",
        "        Parameters\n",
        "        --------\n",
        "        data: pandas.DataFrame\n",
        "            Training data. It contains the transactions of the sessions. It has one column for session IDs, one for item IDs and one for the timestamp of the events (unix timestamps).\n",
        "            It must have a header. Column names are arbitrary, but must correspond to the ones you set during the initialization of the network (session_key, item_key, time_key properties).\n",
        "        '''\n",
        "        data.set_index(np.arange(len(data)), inplace=True)\n",
        "        itemids = data[self.item_key].unique()\n",
        "        n_items = len(itemids)\n",
        "        data = pd.merge(data, pd.DataFrame({self.item_key: itemids, 'ItemIdx': np.arange(len(itemids))}),\n",
        "                        on=self.item_key, how='inner')\n",
        "        sessionids = data[self.session_key].unique()\n",
        "        data = pd.merge(data, pd.DataFrame({self.session_key: sessionids, 'SessionIdx': np.arange(len(sessionids))}),\n",
        "                        on=self.session_key, how='inner')\n",
        "        supp = data.groupby('SessionIdx').size()\n",
        "        session_offsets = np.zeros(len(supp) + 1, dtype=np.int32)\n",
        "        session_offsets[1:] = supp.cumsum()\n",
        "        index_by_sessions = data.sort_values(['SessionIdx', self.time_key]).index.values\n",
        "        supp = data.groupby('ItemIdx').size()\n",
        "        item_offsets = np.zeros(n_items + 1, dtype=np.int32)\n",
        "        item_offsets[1:] = supp.cumsum()\n",
        "        index_by_items = data.sort_values(['ItemIdx', self.time_key]).index.values\n",
        "        self.sims = dict()\n",
        "        for i in range(n_items):\n",
        "            iarray = np.zeros(n_items)\n",
        "            start = item_offsets[i]\n",
        "            end = item_offsets[i + 1]\n",
        "            for e in index_by_items[start:end]:\n",
        "                uidx = data.SessionIdx.values[e]\n",
        "                ustart = session_offsets[uidx]\n",
        "                uend = session_offsets[uidx + 1]\n",
        "                user_events = index_by_sessions[ustart:uend]\n",
        "                iarray[data.ItemIdx.values[user_events]] += 1\n",
        "            iarray[i] = 0\n",
        "            norm = np.power((supp[i] + self.lmbd), self.alpha) * np.power((supp.values + self.lmbd), (1.0 - self.alpha))\n",
        "            norm[norm == 0] = 1\n",
        "            iarray = iarray / norm\n",
        "            indices = np.argsort(iarray)[-1:-1 - self.n_sims:-1]\n",
        "            self.sims[itemids[i]] = pd.Series(data=iarray[indices], index=itemids[indices])\n",
        "\n",
        "    def predict_next(self, session_id, input_item_id, predict_for_item_ids, skip=False, mode_type='view',\n",
        "                     timestamp=0):\n",
        "        '''\n",
        "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "        Parameters\n",
        "        --------\n",
        "        session_id : int or string\n",
        "            The session IDs of the event.\n",
        "        input_item_id : int or string\n",
        "            The item ID of the event. Must be in the set of item IDs of the training set.\n",
        "        predict_for_item_ids : 1D array\n",
        "            IDs of items for which the network should give prediction scores. Every ID must be in the set of item IDs of the training set.\n",
        "        Returns\n",
        "        --------\n",
        "        out : pandas.Series\n",
        "            Prediction scores for selected items on how likely to be the next item of this session. Indexed by the item IDs.\n",
        "        '''\n",
        "        preds = np.zeros(len(predict_for_item_ids))\n",
        "        sim_list = self.sims[input_item_id]\n",
        "        mask = np.in1d(predict_for_item_ids, sim_list.index)\n",
        "        preds[mask] = sim_list[predict_for_item_ids[mask]]\n",
        "        return pd.Series(data=preds, index=predict_for_item_ids)\n"
      ],
      "metadata": {
        "id": "SluPW4JAuzAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'prev_items': [\n",
        "        ['B09W9FND7K', 'B09JSPLN1M'],\n",
        "        ['B076THCGSG', 'B007MO8IME', 'B08MF65MLV', 'B001B'],\n",
        "        ['B0B1LGXWDS', 'B00AZYORS2', 'B0B1LGXWDS', 'B00AZ'],\n",
        "        ['B076THCGSG', 'B007MO8IME', 'B08MF65MLV', 'B001B'],\n",
        "        ['B09W9FND7K', 'B09JSPLN1M']\n",
        "    ],\n",
        "    'next_item': ['B09M7GY217', 'B001B4THSA', 'B0767DTG2Q', 'B001B4THSA', 'B09M7GY217'],\n",
        "    'locale': ['DE', 'DE', 'DE', 'DE', 'DE']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def reformat_dataframe(df):\n",
        "    session_id_col = []\n",
        "    item_id_col = []\n",
        "    time_col = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        session_id = i\n",
        "        for j, item_ids in enumerate(row[\"prev_items\"]):\n",
        "            for item_id in item_ids:\n",
        "                session_id_col.append(session_id)\n",
        "                item_id_col.append(item_id)\n",
        "                time_col.append(j)\n",
        "\n",
        "        session_id_col.append(session_id)\n",
        "        item_id_col.append(row[\"next_item\"])\n",
        "        time_col.append(len(row[\"prev_items\"]))\n",
        "\n",
        "    new_df = pd.DataFrame({\"SessionId\": session_id_col, \"ItemId\": item_id_col, \"Time\": time_col})\n",
        "    return new_df\n",
        "df = reformat_dataframe(df)"
      ],
      "metadata": {
        "id": "weezv7q0t3e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "s7bn9lbnwGNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "dc6347eb-51e9-4a85-f4c4-e602b54e7695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     SessionId      ItemId  Time\n",
              "0            0           B     0\n",
              "1            0           0     0\n",
              "2            0           9     0\n",
              "3            0           W     0\n",
              "4            0           9     0\n",
              "..         ...         ...   ...\n",
              "145          4           L     1\n",
              "146          4           N     1\n",
              "147          4           1     1\n",
              "148          4           M     1\n",
              "149          4  B09M7GY217     2\n",
              "\n",
              "[150 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7142311b-8bd9-4bf7-99de-f92ef0960d16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SessionId</th>\n",
              "      <th>ItemId</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>4</td>\n",
              "      <td>L</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>4</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>4</td>\n",
              "      <td>B09M7GY217</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7142311b-8bd9-4bf7-99de-f92ef0960d16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7142311b-8bd9-4bf7-99de-f92ef0960d16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7142311b-8bd9-4bf7-99de-f92ef0960d16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def reformat_dataframe(df):\n",
        "    session_id_col = []\n",
        "    item_id_col = []\n",
        "    time_col = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        session_id = i\n",
        "        for j, item_ids in enumerate(row[\"prev_items\"]):\n",
        "            for item_id in item_ids:\n",
        "                session_id_col.append(session_id)\n",
        "                item_id_col.append(item_id)\n",
        "                time_col.append(j)\n",
        "\n",
        "    new_df = pd.DataFrame({\"SessionId\": session_id_col, \"ItemId\": item_id_col, \"Time\": time_col})\n",
        "    return new_df\n",
        "\n",
        "data = {\n",
        "    'prev_items': [\n",
        "        ['A', 'B'],\n",
        "        ['A', 'B', 'C', 'D'],\n",
        "        ['B', 'A', 'E', 'F'],\n",
        "        ['A', 'B', 'G', 'H'],\n",
        "        ['A', 'E']\n",
        "    ],\n",
        "    'locale': ['DE', 'DE', 'DE', 'DE', 'DE']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = reformat_dataframe(df)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdAW2l11pXaD",
        "outputId": "f11dbf3d-78e5-4dac-e2cc-add4f6df2474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SessionId ItemId  Time\n",
            "0           0      A     0\n",
            "1           0      B     1\n",
            "2           1      A     0\n",
            "3           1      B     1\n",
            "4           1      C     2\n",
            "5           1      D     3\n",
            "6           2      B     0\n",
            "7           2      A     1\n",
            "8           2      E     2\n",
            "9           2      F     3\n",
            "10          3      A     0\n",
            "11          3      B     1\n",
            "12          3      G     2\n",
            "13          3      H     3\n",
            "14          4      A     0\n",
            "15          4      E     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdfnBvCFv8ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iknn = ItemKNN(n_sims=100, lmbd=20, alpha=0.5, session_key=\"SessionId\",\n",
        "               item_key=\"ItemId\", time_key=\"Time\")\n",
        "iknn.fit(df)"
      ],
      "metadata": {
        "id": "06psWx5jpr9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iknn.sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vZcgo50rxbQ",
        "outputId": "52238162-ad05-4ccc-b6b9-29e36014ac8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': B    0.163299\n",
              " E    0.085280\n",
              " H    0.043644\n",
              " G    0.043644\n",
              " F    0.043644\n",
              " D    0.043644\n",
              " C    0.043644\n",
              " A    0.000000\n",
              " dtype: float64,\n",
              " 'B': A    0.163299\n",
              " H    0.044544\n",
              " G    0.044544\n",
              " F    0.044544\n",
              " D    0.044544\n",
              " C    0.044544\n",
              " E    0.043519\n",
              " B    0.000000\n",
              " dtype: float64,\n",
              " 'C': D    0.047619\n",
              " B    0.044544\n",
              " A    0.043644\n",
              " H    0.000000\n",
              " G    0.000000\n",
              " F    0.000000\n",
              " E    0.000000\n",
              " C    0.000000\n",
              " dtype: float64,\n",
              " 'D': C    0.047619\n",
              " B    0.044544\n",
              " A    0.043644\n",
              " H    0.000000\n",
              " G    0.000000\n",
              " F    0.000000\n",
              " E    0.000000\n",
              " D    0.000000\n",
              " dtype: float64,\n",
              " 'E': A    0.085280\n",
              " F    0.046524\n",
              " B    0.043519\n",
              " H    0.000000\n",
              " G    0.000000\n",
              " E    0.000000\n",
              " D    0.000000\n",
              " C    0.000000\n",
              " dtype: float64,\n",
              " 'F': E    0.046524\n",
              " B    0.044544\n",
              " A    0.043644\n",
              " H    0.000000\n",
              " G    0.000000\n",
              " F    0.000000\n",
              " D    0.000000\n",
              " C    0.000000\n",
              " dtype: float64,\n",
              " 'G': H    0.047619\n",
              " B    0.044544\n",
              " A    0.043644\n",
              " G    0.000000\n",
              " F    0.000000\n",
              " E    0.000000\n",
              " D    0.000000\n",
              " C    0.000000\n",
              " dtype: float64,\n",
              " 'H': G    0.047619\n",
              " B    0.044544\n",
              " A    0.043644\n",
              " H    0.000000\n",
              " F    0.000000\n",
              " E    0.000000\n",
              " D    0.000000\n",
              " C    0.000000\n",
              " dtype: float64}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_similarity(df, alpha, lambda_value):\n",
        "    # Flatten prev_items column\n",
        "    prev_items_flat = np.concatenate(df['prev_items'].values)\n",
        "\n",
        "    # Get unique items and their counts\n",
        "    unique_items, item_counts = np.unique(prev_items_flat, return_counts=True)\n",
        "\n",
        "    # Create an item index mapping for efficient indexing\n",
        "    item_to_index = {item: index for index, item in enumerate(unique_items)}\n",
        "\n",
        "    # Calculate support arrays\n",
        "    supp_i = np.zeros(len(unique_items))\n",
        "    supp_j = np.zeros(len(unique_items))\n",
        "\n",
        "    for items in df['prev_items']:\n",
        "        indices = [item_to_index[item] for item in items]\n",
        "        supp_i[indices] += 1\n",
        "        supp_j[indices] += len(items)\n",
        "\n",
        "    # Create co-occurrence matrix\n",
        "    co_occurrence_matrix = np.zeros((len(unique_items), len(unique_items)), dtype=int)\n",
        "\n",
        "    for items in df['prev_items']:\n",
        "        indices = [item_to_index[item] for item in items]\n",
        "        co_occurrence_matrix[np.ix_(indices, indices)] += 1\n",
        "\n",
        "    # Calculate similarity measure\n",
        "    numerator = co_occurrence_matrix / ((supp_i + lambda_value) ** alpha * (supp_j + lambda_value) ** (1 - alpha))\n",
        "    denominator = np.sum(numerator)\n",
        "    similarity = numerator / denominator\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# Example usage\n",
        "data = {\n",
        "    'prev_items': [\n",
        "        np.array(['A', 'B']),\n",
        "        np.array(['A', 'B', 'C', 'D']),\n",
        "        np.array(['B', 'A', 'E', 'F']),\n",
        "        np.array(['A', 'B', 'G', 'H']),\n",
        "        np.array(['A', 'E']),\n",
        "    ],\n",
        "    'locale': ['DE', 'DE', 'DE', 'DE']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "alpha = 0.5  # Parameter alpha\n",
        "lambda_value = 0.1  # Regularization parameter\n",
        "\n",
        "similarity_matrix = calculate_similarity(df, alpha, lambda_value)\n",
        "print(similarity_matrix)"
      ],
      "metadata": {
        "id": "0Zn08cS4rz5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "bd8cf6ca-eca3-4955-c3e7-400515e5e6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-50db3e30d3b4>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m }\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m  \u001b[0;31m# Parameter alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mlambda_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m  \u001b[0;31m# Regularization parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        ['A', 'B'],\n",
        "        ['A', 'B', 'C', 'D'],\n",
        "        ['B', 'A', 'E', 'F'],\n",
        "        ['A', 'B', 'G', 'H'],\n",
        "        ['A', 'E']"
      ],
      "metadata": {
        "id": "TD2ahfI1-iRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}